{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a95a1eec",
   "metadata": {},
   "source": [
    "# ðŸŽ“ FrugalGPT: Better Quality and Lower Cost for LLM Apps\n",
    "\n",
    "This notebook illustrates the FrugalGPT framework for _building LLM Applications with budget constraints._\n",
    "\n",
    "Below, we will demonstrate two techniques offered by FrugalGPT to build cost-efficient LLM applications. The first techniques, LLMforAll, allows the users to query various LLM APIs via a unified inferface. The sceond one, LLMCascade, automates and optimizes the query process given a user-defined budget constraint.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea3b2c7",
   "metadata": {},
   "source": [
    "## Installation\n",
    "Let us start by installing FrugalGPT (if you haven't yet!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2777650",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, json, copy \n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "sys.path.append(\"src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef14cb0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Next, let us set up the environment. Currently, FrugalGPT leverages LLM APIs from OpenAI (including ChatGPT and GPT-4), AI21, cohere, TextSynth, and Anthropic. Thus we need to set up their API keys. You can still run the notebook without the keys, but API keys are needed if you need FrugalGPT for your own queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2855163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported LLMs: ['textsynth/gptneox_20B', 'textsynth/fairseq_gpt_13B', 'textsynth/gptj_6B', 'openai/text-davinci-002', 'openai/text-davinci-003', 'openai/text-curie-001', 'openai/text-babbage-001', 'openai/text-ada-001', 'openaichat/gpt-3.5-turbo', 'openaichat/gpt-4', 'ai21/j1-jumbo', 'ai21/j1-grande', 'ai21/j1-large', 'ai21/j2-ultra', 'ai21/j2-mid', 'ai21/j2-light', 'cohere/command', 'cohere/base', 'cohere/xlarge', 'cohere/medium', 'anthropic/claude-1', 'anthropic/claude-instant-1', 'anthropic/claude-1-100k']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'\n",
    "os.environ['AI21_STUDIO_API_KEY'] = 'AI21_STUDIO_API_KEY'\n",
    "os.environ['COHERE_STUDIO_API_KEY'] = 'COHERE_STUDIO_API_KEY'\n",
    "os.environ['TEXTSYNTH_API_SECRET_KEY'] = 'TEXTSYNTH_API_SECRET_KEY'\n",
    "os.environ['ANTHROPIC_API_KEY'] = 'ANTHROPIC_API_KEY'\n",
    "from IPython.display import display\n",
    "import FrugalGPT\n",
    "supported_LLM = FrugalGPT.getservicename()\n",
    "print(\"supported LLMs:\",supported_LLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e56f0d",
   "metadata": {},
   "source": [
    "## 1. LLMforAll: One interface for all LLM services\n",
    "Let us first study an example for LLMforAll, an interface that unifies all existing services.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541f755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API: anthropic/claude-1-100k answer:  I apologize, but I do not actually know who Matei Zaharia will be in 2023 or specifics about his future career. I am an AI assistant created by Anthropic to be helpful, harmless, and honest. cost: 0.0016795999999999998\n"
     ]
    }
   ],
   "source": [
    "MyLLMforAll = FrugalGPT.LLMforAll()\n",
    "query = \"Question: Who is Matei Zaharia in 2023?\\nAnswer:\"\n",
    "service_name = supported_LLM[-1]\n",
    "genparams = FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n\\n\\n\\n'])\n",
    "answer = MyLLMforAll.get_completion(query,service_name,genparams=genparams)\n",
    "cost = MyLLMforAll.get_cost()\n",
    "print(\"API:\",service_name,\"answer:\",answer,\"cost:\",cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da4b98",
   "metadata": {},
   "source": [
    "The above code snippet shows how to use LLMforAll. Its function get_completion gives a unified inferface for all LLMs: it takes the query, the generation parameters (such as temperature), and the service name as input, and then gives the corresponding generation. The cost can be obtained by calling get_cost(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488fac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full responses\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service</th>\n",
       "      <th>answer</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>textsynth/gptneox_20B</td>\n",
       "      <td>Matei Zaharia is a computer scientist who wor...</td>\n",
       "      <td>1.772400e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>textsynth/fairseq_gpt_13B</td>\n",
       "      <td>Matei Zaharia is a Romanian politician and me...</td>\n",
       "      <td>7.590000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>textsynth/gptj_6B</td>\n",
       "      <td>The worldâ€™s first self-driving car.\\n\\nMatei ...</td>\n",
       "      <td>2.530000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openai/text-davinci-002</td>\n",
       "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
       "      <td>1.080000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openai/text-davinci-003</td>\n",
       "      <td>In 2023, Matei Zaharia is a computer scientis...</td>\n",
       "      <td>1.300000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai/text-curie-001</td>\n",
       "      <td>Matei Zaharia will be 73 years old in 2023.</td>\n",
       "      <td>5.600000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>openai/text-babbage-001</td>\n",
       "      <td>Matei Zaharia is a Romanian-born American bus...</td>\n",
       "      <td>1.500000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>openai/text-ada-001</td>\n",
       "      <td>\\n\\nMatei Zaharia is a Russian-born American b...</td>\n",
       "      <td>2.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openaichat/gpt-3.5-turbo</td>\n",
       "      <td>As an AI language model, I cannot predict the ...</td>\n",
       "      <td>1.460000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>openaichat/gpt-4</td>\n",
       "      <td>As an AI, I cannot predict the future or provi...</td>\n",
       "      <td>3.660000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ai21/j1-jumbo</td>\n",
       "      <td>Matei Zaharia is 42 years old.\\nQuestion: Wha...</td>\n",
       "      <td>1.750000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ai21/j1-grande</td>\n",
       "      <td>Matei Zaharia will be 33 years old.\\nQuestion...</td>\n",
       "      <td>4.800000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai21/j1-large</td>\n",
       "      <td>Matei Zaharia is 43 years old in 2023.\\nQuest...</td>\n",
       "      <td>1.800000e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ai21/j2-ultra</td>\n",
       "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
       "      <td>8.850000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ai21/j2-mid</td>\n",
       "      <td>Matei Zaharia is a computer scientist and ent...</td>\n",
       "      <td>5.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ai21/j2-light</td>\n",
       "      <td>Matei Zaharia is a Romanian-American computer...</td>\n",
       "      <td>4.920000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cohere/command</td>\n",
       "      <td>Matei Zaharia is a Romanian-born American com...</td>\n",
       "      <td>7.350000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cohere/base</td>\n",
       "      <td>Matei Zaharia is a Romanian-Canadian computer...</td>\n",
       "      <td>7.350000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cohere/xlarge</td>\n",
       "      <td>Matei Zaharia is a Romanian-Canadian computer...</td>\n",
       "      <td>1.225000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cohere/medium</td>\n",
       "      <td>Matei Zaharia is the founder of the company C...</td>\n",
       "      <td>1.225000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>anthropic/claude-1</td>\n",
       "      <td>I apologize, but I do not have information ab...</td>\n",
       "      <td>1.810320e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>anthropic/claude-instant-1</td>\n",
       "      <td>Matei Zaharia is a computer scientist and ent...</td>\n",
       "      <td>3.015800e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>anthropic/claude-1-100k</td>\n",
       "      <td>I apologize, but I do not actually know who M...</td>\n",
       "      <td>1.679600e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       service  \\\n",
       "0        textsynth/gptneox_20B   \n",
       "1    textsynth/fairseq_gpt_13B   \n",
       "2            textsynth/gptj_6B   \n",
       "3      openai/text-davinci-002   \n",
       "4      openai/text-davinci-003   \n",
       "5        openai/text-curie-001   \n",
       "6      openai/text-babbage-001   \n",
       "7          openai/text-ada-001   \n",
       "8     openaichat/gpt-3.5-turbo   \n",
       "9             openaichat/gpt-4   \n",
       "10               ai21/j1-jumbo   \n",
       "11              ai21/j1-grande   \n",
       "12               ai21/j1-large   \n",
       "13               ai21/j2-ultra   \n",
       "14                 ai21/j2-mid   \n",
       "15               ai21/j2-light   \n",
       "16              cohere/command   \n",
       "17                 cohere/base   \n",
       "18               cohere/xlarge   \n",
       "19               cohere/medium   \n",
       "20          anthropic/claude-1   \n",
       "21  anthropic/claude-instant-1   \n",
       "22     anthropic/claude-1-100k   \n",
       "\n",
       "                                               answer          cost  \n",
       "0    Matei Zaharia is a computer scientist who wor...  1.772400e-03  \n",
       "1    Matei Zaharia is a Romanian politician and me...  7.590000e-04  \n",
       "2    The worldâ€™s first self-driving car.\\n\\nMatei ...  2.530000e-04  \n",
       "3    Matei Zaharia is a Romanian-American computer...  1.080000e-03  \n",
       "4    In 2023, Matei Zaharia is a computer scientis...  1.300000e-03  \n",
       "5         Matei Zaharia will be 73 years old in 2023.  5.600000e-05  \n",
       "6    Matei Zaharia is a Romanian-born American bus...  1.500000e-05  \n",
       "7   \\n\\nMatei Zaharia is a Russian-born American b...  2.000000e-05  \n",
       "8   As an AI language model, I cannot predict the ...  1.460000e-04  \n",
       "9   As an AI, I cannot predict the future or provi...  3.660000e-03  \n",
       "10   Matei Zaharia is 42 years old.\\nQuestion: Wha...  1.750000e-02  \n",
       "11   Matei Zaharia will be 33 years old.\\nQuestion...  4.800000e-03  \n",
       "12   Matei Zaharia is 43 years old in 2023.\\nQuest...  1.800000e-03  \n",
       "13   Matei Zaharia is a Romanian-American computer...  8.850000e-04  \n",
       "14   Matei Zaharia is a computer scientist and ent...  5.000000e-04  \n",
       "15   Matei Zaharia is a Romanian-American computer...  4.920000e-04  \n",
       "16   Matei Zaharia is a Romanian-born American com...  7.350000e-07  \n",
       "17   Matei Zaharia is a Romanian-Canadian computer...  7.350000e-07  \n",
       "18   Matei Zaharia is a Romanian-Canadian computer...  1.225000e-04  \n",
       "19   Matei Zaharia is the founder of the company C...  1.225000e-04  \n",
       "20   I apologize, but I do not have information ab...  1.810320e-03  \n",
       "21   Matei Zaharia is a computer scientist and ent...  3.015800e-04  \n",
       "22   I apologize, but I do not actually know who M...  1.679600e-03  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = MyLLMforAll.get_completion_allservice(query, supported_LLM, genparams=genparams)\n",
    "print(\"full responses\")\n",
    "display(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0989f2ac",
   "metadata": {},
   "source": [
    "## 2. LLMCascade: Optimizing performance within budget constraints \n",
    "Next let us use LLMCascade to automatically optimize the overall performance given a budget constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499247a7",
   "metadata": {},
   "source": [
    "### Example usage: predicting gold price trends from financial news\n",
    "Let us first create a few NLP queries that asks LLM to predict gold price trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b1f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = [['Q: april gold down 20 cents to settle at $1,116.10/oz\\nA:', 'down','0'],\n",
    "       ['Q: gold suffers third straight daily decline\\nA:', 'down','1'],\n",
    "       ['Q: Gold futures edge up after two-session decline\\nA:', 'up','2'],\n",
    "       ['Q: Dec. gold climbs $9.40, or 0.7%, to settle at $1,356.90/oz\\nA:','up','3'],\n",
    "       ['Q: Gold struggles; silver slides, base metals falter\\nA:','up','4'],\n",
    "       ['Q: feb. gold ends up $9.60, or 1.1%, at $901.60 an ounce\\nA:','up','5'],\n",
    "        ['Q: dent research : is gold\\'s day in the sun coming soon?\\nA:','none','6']\n",
    "      ]\n",
    "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
    "raw_data = copy.deepcopy(dev)\n",
    "data = FrugalGPT.formatdata(dev,prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935ff2",
   "metadata": {},
   "source": [
    "Next let us load a LLMCascade instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1775ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=0.000665)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ebf172",
   "metadata": {},
   "source": [
    "Let us take a look on LLMCascade's generation on one query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91e9935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Q: Gold futures edge up after two-session decline\n",
      "A:\n",
      "FrugalGPT LLMCascade answer:  up\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "query = data[index][0]\n",
    "query_raw = raw_data[index][0]\n",
    "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])\n",
    "answer = MyCascade.get_completion(query=query,genparams=genparams)\n",
    "cost = MyCascade.get_cost()\n",
    "print(\"query:\",query_raw)\n",
    "print(\"FrugalGPT LLMCascade answer:\",answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a14d27",
   "metadata": {},
   "source": [
    "Now we can pass all the queries to both LLMCascade and vanilla GPT-4, and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46742343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrugalGPT LLMCascade generations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>down</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id answer ref_answer      cost\n",
       "0   0   down       down  0.000056\n",
       "1   1   down       down  0.000054\n",
       "2   2     up         up  0.000055\n",
       "3   3     up         up  0.000058\n",
       "4   4   down         up  0.000055\n",
       "5   5     up         up  0.000057\n",
       "6   6   none       none  0.000497"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'em': 0.8571428571428571, 'cost': 0.00011888571428571427}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 generations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.00678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.00645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>down</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.00663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id answer ref_answer     cost\n",
       "0   0   down       down  0.00678\n",
       "1   1   down       down  0.00645\n",
       "2   2     up         up  0.00651\n",
       "3   3     up         up  0.00705\n",
       "4   4   down         up  0.00657\n",
       "5   5     up         up  0.00699\n",
       "6   6   none       none  0.00663"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'em': 0.8571428571428571, 'cost': 0.006711428571428572}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batch generation\n",
    "result = MyCascade.get_completion_batch(queries=data,genparams=genparams)\n",
    "result_GPT4 = MyLLMforAll.get_completion_batch(queries=data,genparams=genparams,service_name='openaichat/gpt-4')\n",
    "print(\"FrugalGPT LLMCascade generations\")\n",
    "display(result)\n",
    "display(FrugalGPT.compute_score(result))\n",
    "print(\"GPT-4 generations\")\n",
    "display(result_GPT4)\n",
    "display(FrugalGPT.compute_score(result_GPT4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0916d06",
   "metadata": {},
   "source": [
    "Overall, FrugalGPT LLMCascade gives the same performance but incurs a much smaller cost. This data is of course quite small; Later we will see the evaluation on a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e58e84",
   "metadata": {},
   "source": [
    "### Using FrugalGPT-LLMCascade for your own data\n",
    "Interested in using FrugalGPT for your own data? No problem! The following code snippnet demonstrates how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd3cc10",
   "metadata": {},
   "source": [
    "The first thing is to load the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d77884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dev = FrugalGPT.loadcsvdata(\"data/HEADLINES/train.csv\")\n",
    "dev = dev[0:10]\n",
    "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
    "data = FrugalGPT.formatdata(dev,prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2bd07",
   "metadata": {},
   "source": [
    "Second, specify the budget per query, and then train the model. Warning: This can take a while on large datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7730973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/FrugalLLM/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:10, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663858</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663796</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663670</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663486</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.663241</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662938</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662582</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662167</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/FrugalLLM/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:11, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712168</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712062</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711848</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711504</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.711062</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.709063</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/FrugalLLM/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:10, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.760674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.760010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.759138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.758036</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.756688</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.755082</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/FrugalLLM/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:11, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761380</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.761150</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.760674</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.760010</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.759138</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.758036</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.756688</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.755082</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the model\n",
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "service_names = ['openaichat/gpt-3.5-turbo','openaichat/gpt-4','ai21/j1-large','textsynth/gptj_6B']\n",
    "result = MyCascade.train(data,budget=100,service_names=service_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3a313dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "MyCascade.save(savepath=\"strategy/TEST/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b8b79",
   "metadata": {},
   "source": [
    "Now the model has been saved to disk. You can load it as follows for future applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4422dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "MyCascade.load(loadpath=\"strategy/TEST/\",budget=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c2ffc",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "Now let us evaluate the performance of FrugalGPT. We use LLMCascade on the HEADLINES dataset as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87cb438",
   "metadata": {},
   "source": [
    "First, we load the evaluation dataset and the LLMCascade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "119692bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data size: 5000\n"
     ]
    }
   ],
   "source": [
    "test = FrugalGPT.loadcsvdata(\"data/HEADLINES/test.csv\")\n",
    "prefix = open('config/prompt/HEADLINES/prefix_e8.txt').read()\n",
    "data_eval = FrugalGPT.formatdata(test,prefix)\n",
    "print(\"test data size:\",len(data_eval))\n",
    "MyCascade = FrugalGPT.LLMCascade()\n",
    "MyCascade.load(loadpath=\"strategy/HEADLINES/\",budget=0.000665)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b5a0c",
   "metadata": {},
   "source": [
    "And then let us evaluate it on the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c844c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 generations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6556</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5832</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.00666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5618</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.00666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4205</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.00660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842</td>\n",
       "      <td>up</td>\n",
       "      <td>down</td>\n",
       "      <td>0.00654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>8376</td>\n",
       "      <td>neutral</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4242</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.00654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>663</td>\n",
       "      <td>down</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>6890</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.00648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>6311</td>\n",
       "      <td>none</td>\n",
       "      <td>up</td>\n",
       "      <td>0.00663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id   answer ref_answer     cost\n",
       "0     6556       up         up  0.00660\n",
       "1     5832     none       none  0.00666\n",
       "2     5618     none       none  0.00666\n",
       "3     4205     down       down  0.00660\n",
       "4      842       up       down  0.00654\n",
       "...    ...      ...        ...      ...\n",
       "4995  8376  neutral         up  0.00651\n",
       "4996  4242     down       down  0.00654\n",
       "4997   663     down         up  0.00660\n",
       "4998  6890  neutral    neutral  0.00648\n",
       "4999  6311     none         up  0.00663\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'em': 0.8556, 'cost': 0.006661218000000001}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrugalGPT LLMCascade generations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>ref_answer</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6556</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5832</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5618</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4205</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>842</td>\n",
       "      <td>up</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>8376</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4242</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>663</td>\n",
       "      <td>down</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>6890</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>6311</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       _id    answer ref_answer      cost\n",
       "0     6556        up         up  0.000055\n",
       "1     5832      none       none  0.000499\n",
       "2     5618      none       none  0.000499\n",
       "3     4205      down       down  0.000055\n",
       "4      842        up       down  0.000055\n",
       "...    ...       ...        ...       ...\n",
       "4995  8376        up         up  0.000055\n",
       "4996  4242      down       down  0.000055\n",
       "4997   663      down         up  0.000495\n",
       "4998  6890   neutral    neutral  0.000054\n",
       "4999  6311        up         up  0.000055\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'em': 0.8594, 'cost': 0.00064688504}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genparams=FrugalGPT.GenerationParameter(max_tokens=50, temperature=0.1, stop=['\\n'])\n",
    "result_GPT4 = MyLLMforAll.get_completion_batch(queries=data_eval,genparams=genparams,service_name='openaichat/gpt-4')\n",
    "print(\"GPT-4 generations\")\n",
    "display(result_GPT4)\n",
    "display(FrugalGPT.compute_score(result_GPT4))\n",
    "result = MyCascade.get_completion_batch(queries=data_eval,genparams=genparams)\n",
    "print(\"FrugalGPT LLMCascade generations\")\n",
    "display(result)\n",
    "display(FrugalGPT.compute_score(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f02a0",
   "metadata": {},
   "source": [
    "Overall, LLMCascade achieves better performance than GPT-4 with a 10x smaller cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
